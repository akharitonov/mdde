package dev.jcri.mdde.registry.benchmark.ycsb.stats.local;

import com.opencsv.exceptions.CsvValidationException;
import dev.jcri.mdde.registry.benchmark.ycsb.stats.IStatsCollector;
import dev.jcri.mdde.registry.benchmark.ycsb.stats.result.FragmentBenchmarkStats;
import dev.jcri.mdde.registry.benchmark.ycsb.stats.result.NodeBenchmarkStats;
import dev.jcri.mdde.registry.exceptions.MddeRegistryException;
import dev.jcri.mdde.registry.shared.benchmark.ycsb.stats.ClientStatsCSVReader;
import dev.jcri.mdde.registry.shared.benchmark.ycsb.stats.ClientStatsCSVWriter;
import dev.jcri.mdde.registry.shared.benchmark.ycsb.stats.LogActions;
import dev.jcri.mdde.registry.store.IReadCommandHandler;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.io.File;
import java.io.IOException;
import java.nio.file.*;
import java.util.*;

/**
 * YCSB stats collector designed to read text file based statistics log generated by the running YCSB clients.
 *
 * Suitable when YCSB is invoked in a CLI mode locally.
 *
 * Client creates 2 files while running, first is a flag status code indicating the client ID and existence, 2nd is the
 * actual CSV file.
 *
 * Flag file: client_generated_id.mdde
 * Log file: same_client_generated_id.csv
 */
public class LocalClientStatsCSVCollector implements IStatsCollector {
    private static final Logger logger = LogManager.getLogger(LocalClientStatsCSVCollector.class);

    private final String _logsDir;
    private final Character _delimiter;
    private final IReadCommandHandler _storeReadAccess;

    /**
     * Constructor
     * @param logsFolder Folder where YCSB clients are going to write logs into.
     */
    public LocalClientStatsCSVCollector(String logsFolder,
                                        Character delimiter,
                                        IReadCommandHandler storeReader) throws IOException{
        Objects.requireNonNull(logsFolder, "LocalClientStatsLogCollector requires a folder to look for log");
        Objects.requireNonNull(delimiter, "CSV delimiter is not specified");
        Objects.requireNonNull(storeReader, "Read-only access to the registry is required for this collector");
        _delimiter = delimiter;
        _storeReadAccess = storeReader;
        if (logsFolder.isBlank()){
            throw new IllegalArgumentException("logsFolder must be a valid path");
        }
        var normalizedPath = Paths.get(logsFolder).toAbsolutePath().normalize().toString();
        var logsDir = new File(normalizedPath);
        if (logsDir.exists() && logsDir.isFile()) {
            throw new NotDirectoryException(normalizedPath);
        }
        boolean mkdirsRes = logsDir.mkdirs();
        _logsDir = normalizedPath;
        logger.trace("New YCSB stats logs directory was created: {}", mkdirsRes);
    }

    @Override
    public boolean getStatsReady() throws IOException {
        int flagFiles = 0;
        int doneFlagFiles = 0;
        var fNamePattern = String.format("*.%s", ClientStatsCSVWriter.STATUS_FILE_EXTENSION);

        try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(_logsDir), fNamePattern)) {
            for (Path file: stream) {
                var fileName = file.getFileName();
                if(fileName.startsWith(ClientStatsCSVWriter.STATUS_FILE_FINAL_PREFIX)){
                    doneFlagFiles++;
                }
                else{
                    flagFiles ++;
                }
            }
        }
        return flagFiles == doneFlagFiles;
    }

    @Override
    public List<NodeBenchmarkStats> getFragmentStats() throws IOException, MddeRegistryException {
        // Get which fragments belong to which nodes
        var knownFragments = _storeReadAccess.getAllFragmentIds();
        Map<String, Set<String>> fragmentsTuples = new HashMap<>();
        for(var fragment: knownFragments){
            fragmentsTuples.put(fragment, _storeReadAccess.getFragmentTuples(fragment));
        }
        Map<String, String> tupleFragment = new HashMap<>();
        for(var entry: fragmentsTuples.entrySet()){
            for(var tupleId: entry.getValue()){
                tupleFragment.put(tupleId, entry.getKey());
            }
        }

        // Read results
        Map<String, Map<String, FragmentBenchmarkStats>> res = new HashMap<>();

        var fNamePattern = String.format("*.%s", ClientStatsCSVWriter.LOG_FILE_EXTENSION);
        try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(_logsDir), fNamePattern)) {
            for (Path logFile: stream) {
                var logReader = new ClientStatsCSVReader(logFile.toString()).reader();
                String [] nextLine;
                while ((nextLine = logReader.readNext()) != null) {
                    var nodeId = nextLine[2];
                    if (!res.containsKey(nodeId)){
                        res.put(nodeId, new HashMap<>());
                    }
                    var nodeResList = res.get(nodeId);
                    var fragmentId = tupleFragment.get(nextLine[1]);
                    if(!nodeResList.containsKey(fragmentId)){
                        nodeResList.put(fragmentId, new FragmentBenchmarkStats(fragmentId, 0));
                    }
                    var fragmentStat = nodeResList.get(fragmentId);
                    if(nextLine[0].equals(LogActions.READ.toString())){
                        fragmentStat.incrementReads();
                    }
                }
            }
        } catch (CsvValidationException e) {
            throw new IOException("Failed to read the stats log", e);
        }
        List<NodeBenchmarkStats> result = new ArrayList<>();
        for(var entry: res.entrySet()){
            var newNodeStats = new NodeBenchmarkStats(entry.getKey(), entry.getValue().values());
            result.add(newNodeStats);
        }
        return result;
    }

    /**
     * Delete processed stats files for this run
     * @throws IOException
     */
    @Override
    public void close() throws IOException {
        var fNamePattern = String.format("*.{%s, %s}}",
                ClientStatsCSVWriter.STATUS_FILE_EXTENSION,
                ClientStatsCSVWriter.LOG_FILE_EXTENSION);
        try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(_logsDir), fNamePattern)) {
            for (Path file: stream) {
                Files.delete(file);
            }
        }
    }
}
